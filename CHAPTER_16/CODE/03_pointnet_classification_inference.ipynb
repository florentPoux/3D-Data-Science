{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "General Information\n",
    "* Created by: \ud83e\udd8a Florent Poux. \n",
    "* Copyright: Florent Poux.\n",
    "* License: MIT\n",
    "* Status: Confidential\n",
    "\n",
    "Dependencies:\n",
    "* Anaconda or Miniconda\n",
    "* An Anaconda new environment\n",
    "* Libraries as described in the Chapter\n",
    "\n",
    "Have fun with this Code Solution.\n",
    "\n",
    "\ud83c\udfb5 Note: Styling was not taken care of at this stage.\n",
    "\n",
    "Enjoy!\n",
    "\"\"\"\n",
    "\n",
    "#%%\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import torch\n",
    "import scipy.spatial.distance\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%% Dataset Path\n",
    "\n",
    "path = Path(\"../DATA/ModelNet10/\")\n",
    "\n",
    "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
    "classes = {folder: i for i, folder in enumerate(folders)};\n",
    "classes\n",
    "\n",
    "#%% Dataset Preparation\n",
    "\n",
    "# Read Off File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_off(file):\n",
    "    if 'OFF' != file.readline().strip():\n",
    "        raise('Not a valid OFF header')\n",
    "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "    return verts, faces\n",
    "\n",
    "# Point Sampler\n",
    "class PointSampler(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def triangle_area(self, pt1, pt2, pt3):\n",
    "        side_a = np.linalg.norm(pt1 - pt2)\n",
    "        side_b = np.linalg.norm(pt2 - pt3)\n",
    "        side_c = np.linalg.norm(pt3 - pt1)\n",
    "        s = 0.5 * ( side_a + side_b + side_c)\n",
    "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
    "\n",
    "    def sample_point(self, pt1, pt2, pt3):\n",
    "        # barycentric coordinates on a triangle\n",
    "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
    "        s, t = sorted([random.random(), random.random()])\n",
    "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
    "        return (f(0), f(1), f(2))\n",
    "        \n",
    "    \n",
    "    def __call__(self, mesh):\n",
    "        verts, faces = mesh\n",
    "        verts = np.array(verts)\n",
    "        areas = np.zeros((len(faces)))\n",
    "\n",
    "        for i in range(len(areas)):\n",
    "            areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
    "                                           verts[faces[i][1]],\n",
    "                                           verts[faces[i][2]]))\n",
    "            \n",
    "        sampled_faces = (random.choices(faces, \n",
    "                                      weights=areas,\n",
    "                                      cum_weights=None,\n",
    "                                      k=self.output_size))\n",
    "        \n",
    "        sampled_points = np.zeros((self.output_size, 3))\n",
    "\n",
    "        for i in range(len(sampled_faces)):\n",
    "            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
    "                                                   verts[sampled_faces[i][1]],\n",
    "                                                   verts[sampled_faces[i][2]]))\n",
    "        \n",
    "        return sampled_points\n",
    "\n",
    "\n",
    "\n",
    "# Data Normalization\n",
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        \n",
    "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
    "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "\n",
    "        return  norm_pointcloud\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        return torch.from_numpy(pointcloud)\n",
    "\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "                                PointSampler(1024),\n",
    "                                Normalize(),\n",
    "                                ToTensor()\n",
    "                              ])\n",
    "\n",
    "#%% Custom Pytorch PointCloudDataset for ModelNet10\n",
    "\n",
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.transforms = transform if not valid else default_transforms()\n",
    "        self.valid = valid\n",
    "        self.files = []\n",
    "        for category in self.classes.keys():\n",
    "            new_dir = root_dir/Path(category)/folder\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.off'):\n",
    "                    sample = {}\n",
    "                    sample['pcd_path'] = new_dir/file\n",
    "                    sample['category'] = category\n",
    "                    self.files.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __preproc__(self, file):\n",
    "        verts, faces = read_off(file)\n",
    "        if self.transforms:\n",
    "            pointcloud = self.transforms((verts, faces))\n",
    "        return pointcloud\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            pointcloud = self.__preproc__(f)\n",
    "        return {'pointcloud': pointcloud, \n",
    "                'category': self.classes[category]}\n",
    "\n",
    "\n",
    "#%% Inference Def\n",
    "\n",
    "valid_ds = PointCloudData(path, valid=True, folder='test', transform=default_transforms)\n",
    "\n",
    "#\n",
    "inv_classes = {i: cat for cat, i in valid_ds.classes.items()};\n",
    "\n",
    "print('Valid dataset size: ', len(valid_ds))\n",
    "print('Sample pointcloud shape: ', valid_ds[0]['pointcloud'].size())\n",
    "print('Class: ', inv_classes[valid_ds[0]['category']])\n",
    "\n",
    "#%%\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)\n",
    "\n",
    "#%% Definition of PointNet\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "   def __init__(self, k=3):\n",
    "      super().__init__()\n",
    "      self.k=k\n",
    "      self.conv1 = nn.Conv1d(k,64,1)\n",
    "      self.conv2 = nn.Conv1d(64,128,1)\n",
    "      self.conv3 = nn.Conv1d(128,1024,1)\n",
    "      self.fc1 = nn.Linear(1024,512)\n",
    "      self.fc2 = nn.Linear(512,256)\n",
    "      self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(64)\n",
    "      self.bn2 = nn.BatchNorm1d(128)\n",
    "      self.bn3 = nn.BatchNorm1d(1024)\n",
    "      self.bn4 = nn.BatchNorm1d(512)\n",
    "      self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "   def forward(self, input):\n",
    "      # input.shape == (bs,n,3)\n",
    "      bs = input.size(0)\n",
    "      xb = F.relu(self.bn1(self.conv1(input)))\n",
    "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "      flat = nn.Flatten(1)(pool)\n",
    "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "      \n",
    "      #initialize as identity\n",
    "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "      if xb.is_cuda:\n",
    "        init=init.cuda()\n",
    "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "      return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "   def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "       \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "       \n",
    "   def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output), matrix3x3, matrix64x64\n",
    "\n",
    "\n",
    "\n",
    "#%% Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#%%\n",
    "\n",
    "# pointnet = PointNet()\n",
    "# pointnet.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPrediction(inputs, i, classes, labels, preds):\n",
    "    xs, ys, zs = inputs[i].numpy().T\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,7))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    img = ax.scatter(xs, ys, zs, c=zs, cmap=plt.hot())\n",
    "    fig.colorbar(img)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "    ax.set_xlim([-1, 1])\n",
    "    ax.set_ylim([-1, 1])\n",
    "    ax.set_zlim([-1, 1])\n",
    "    \n",
    "    try:\n",
    "        GTName = list(classes.keys())[list(classes.values()).index(labels[i].numpy())]\n",
    "    except:\n",
    "        GTName = 'Unknown'    \n",
    "    \n",
    "    PRED = list(classes.keys())[list(classes.values()).index(preds[i].numpy())]\n",
    "    \n",
    "    plt.title(f'GT: {GTName}, Prediction: {PRED}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#%% Tests\n",
    "\n",
    "\n",
    "\n",
    "pointnet = PointNet()\n",
    "pointnet.load_state_dict(torch.load(\"../MODEL/pointnet_classification_15.torch\"))\n",
    "pointnet.eval();\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(valid_loader):\n",
    "        print('Batch [%4d / %4d]' % (i+1, len(valid_loader)))\n",
    "                   \n",
    "        inputs, labels = data['pointcloud'].float(), data['category']\n",
    "        outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        for j in range(len(labels)):\n",
    "            plotPrediction(inputs, j, classes, labels, preds)\n",
    "        \n",
    "        all_preds += list(preds.numpy())\n",
    "        all_labels += list(labels.numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds);\n",
    "cm\n",
    "\n",
    "#%%\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor',\n",
    " 'night_stand', 'sofa', 'table', 'toilet']\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=target_names))\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "\n",
    "# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes.keys()), normalize=True)\n",
    "\n",
    "#%% External dataset\n",
    "\n",
    "#Load and Normalize\n",
    "\n",
    "pcd = o3d.io.read_point_cloud('../DATA/FURNITURES/verviers_chair.ply')\n",
    "\n",
    "pcd = pcd.farthest_point_down_sample(1024)\n",
    "\n",
    "center = pcd.get_center()\n",
    "pcd.translate(-center)\n",
    "\n",
    "scale = 1 / np.max(np.abs(np.asarray(pcd.points)))\n",
    "pcd.scale(scale, center=(0, 0, 0))\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "#Tensorize\n",
    "\n",
    "pcd_in = torch.from_numpy(np.asarray(pcd.points)).float()\n",
    "\n",
    "#%% Prediction\n",
    "\n",
    "with torch.no_grad():\n",
    "        input_data = pcd_in.unsqueeze(0)     \n",
    "        output, __, __ = pointnet(input_data.transpose(1,2))\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        \n",
    "        plotPrediction(input_data, 0, classes, 'None', preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}