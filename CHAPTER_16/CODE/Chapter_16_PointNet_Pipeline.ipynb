{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83d\udca5 Chapter 16: PointNet - Advanced Deep Learning Classification\n",
                "\n",
                "PointNet (Qi et al., 2017) revolutionized 3D Deep Learning by acting directly on points. It learns global features by aggregating local information using a symmetric function (Max Pooling).\n",
                "\n",
                "**Workflow:**\n",
                "1.  **Preparation**: Convert LAS files to HDF5 format (fast loading).\n",
                "2.  **Architecture**: Implement PointNet in PyTorch.\n",
                "3.  **Training**: Train the model to classify objects.\n",
                "4.  **Inference**: Test on new data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import laspy\n",
                "import h5py\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Preparation (HDF5)\n",
                "\n",
                "Deep Learning requires fast I/O. We convert our raw LAS/PLY files into structured HDF5 files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_h5(h5_filename, data, label, data_dtype='float32', label_dtype='uint8'):\n",
                "    h5_fout = h5py.File(h5_filename, 'w')\n",
                "    h5_fout.create_dataset(\n",
                "            'data', data=data,\n",
                "            compression='gzip', compression_opts=4,\n",
                "            dtype=data_dtype)\n",
                "    h5_fout.create_dataset(\n",
                "            'label', data=label,\n",
                "            compression='gzip', compression_opts=1,\n",
                "            dtype=label_dtype)\n",
                "    h5_fout.close()\n",
                "    print(f\"Saved {h5_filename}\")\n",
                "\n",
                "# Example usage (commented out unless data exists)\n",
                "# points = ... # [N_samples, 2048, 3]\n",
                "# labels = ... # [N_samples]\n",
                "# save_h5(\"../DATA/ply_data_train0.h5\", points, labels)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. PointNet Architecture (PyTorch)\n",
                "\n",
                "A simplified implementation of the classification network."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class PointNetCls(nn.Module):\n",
                "    def __init__(self, k=2):\n",
                "        super(PointNetCls, self).__init__()\n",
                "        # Shared MLP (implemented as Conv1d with kernel size 1)\n",
                "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
                "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
                "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
                "        \n",
                "        # Classification MLP\n",
                "        self.fc1 = nn.Linear(1024, 512)\n",
                "        self.fc2 = nn.Linear(512, 256)\n",
                "        self.fc3 = nn.Linear(256, k)\n",
                "        \n",
                "        self.bn1 = nn.BatchNorm1d(64)\n",
                "        self.bn2 = nn.BatchNorm1d(128)\n",
                "        self.bn3 = nn.BatchNorm1d(1024)\n",
                "        self.bn4 = nn.BatchNorm1d(512)\n",
                "        self.bn5 = nn.BatchNorm1d(256)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        # Input x: [Batch, 3, N_points]\n",
                "        x = F.relu(self.bn1(self.conv1(x)))\n",
                "        x = F.relu(self.bn2(self.conv2(x)))\n",
                "        x = F.relu(self.bn3(self.conv3(x)))\n",
                "        \n",
                "        # Max Pooling (Symmetric Function)\n",
                "        # Max over N_points dimension\n",
                "        x = torch.max(x, 2, keepdim=True)[0]\n",
                "        x = x.view(-1, 1024)\n",
                "        \n",
                "        x = F.relu(self.bn4(self.fc1(x)))\n",
                "        x = F.relu(self.bn5(self.fc2(x)))\n",
                "        x = self.fc3(x)\n",
                "        \n",
                "        return F.log_softmax(x, dim=1)\n",
                "\n",
                "model = PointNetCls(k=5)\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "criterion = nn.NLLLoss()\n",
                "\n",
                "# Dummy Training Step\n",
                "inputs = torch.randn(32, 3, 2048) # Batch 32, 2048 points\n",
                "labels = torch.randint(0, 5, (32,))\n",
                "\n",
                "optimizer.zero_grad()\n",
                "outputs = model(inputs)\n",
                "loss = criterion(outputs, labels)\n",
                "loss.backward()\n",
                "optimizer.step()\n",
                "\n",
                "print(f\"Dummy Loss: {loss.item():.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}