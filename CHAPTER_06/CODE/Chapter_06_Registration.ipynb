{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83e\udde9 Chapter 6: Precision 3D - Part 2: Registration\n",
                "\n",
                "In this second part of Chapter 6, we tackle **Point Cloud Registration**. This is the process of aligning two point clouds into a single coordinate system. It is fundamental for stitching together 3D scans.\n",
                "\n",
                "**Objectives:**\n",
                "1.  **Global Registration**: Aligning clouds without prior knowledge using RANSAC and FPFH features.\n",
                "2.  **Local Registration**: Refining the alignment using the Iterative Closest Point (ICP) algorithm."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import open3d as o3d\n",
                "import copy\n",
                "import time"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Source and Target Clouds\n",
                "\n",
                "We have a \"Source\" cloud (to be moved) and a \"Target\" cloud (fixed)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "source_path = \"../DATA/registration_source.ply\"\n",
                "target_path = \"../DATA/global_todo_registration_target.ply\"\n",
                "\n",
                "source = o3d.io.read_point_cloud(source_path)\n",
                "target = o3d.io.read_point_cloud(target_path)\n",
                "\n",
                "# Visualize initial state\n",
                "print(\"Initial State: Source is NOT aligned with Target.\")\n",
                "source.paint_uniform_color([1, 0.7, 0]) # Yellow Source\n",
                "target.paint_uniform_color([0, 0.6, 0.9]) # Blue Target\n",
                "o3d.visualization.draw_geometries([source, target])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Extraction (FPFH)\n",
                "\n",
                "Before we can align them globally, we need to describe the geometry around each point using **Fast Point Feature Histograms (FPFH)**. This allows us to find matching points even if they are far apart.\n",
                "\n",
                "We also downsample the point clouds to speed up the process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_point_cloud(pcd, voxel_size):\n",
                "    # 1. Downsample\n",
                "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
                "    \n",
                "    # 2. Estimate Normals (Required for FPFH)\n",
                "    radius_normal = voxel_size * 2.0\n",
                "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
                "    \n",
                "    # 3. Compute FPFH Features\n",
                "    radius_feature = voxel_size * 5.0\n",
                "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
                "        pcd_down,\n",
                "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
                "    \n",
                "    return pcd_down, pcd_fpfh\n",
                "\n",
                "voxel_size = 1.5 # Coarse voxel size for Global Registration\n",
                "source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
                "target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
                "\n",
                "print(f\"Source Downsampled: {len(source_down.points)} points.\")\n",
                "print(f\"Target Downsampled: {len(target_down.points)} points.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Global Registration (RANSAC)\n",
                "\n",
                "We use **RANSAC (Random Sample Consensus)** to find match correspondences between our FPFH features. This gives us a rough match."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
                "    distance_threshold = voxel_size * 1.5\n",
                "    \n",
                "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
                "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
                "        distance_threshold,\n",
                "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
                "        3, # Match 3 points at least\n",
                "        [\n",
                "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
                "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
                "        ],\n",
                "        o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999)\n",
                "    )\n",
                "    return result\n",
                "\n",
                "start = time.time()\n",
                "result_ransac = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
                "print(f\"Global Registration took {time.time() - start:.2f} sec.\")\n",
                "print(\"Transformation Matrix:\\n\", result_ransac.transformation)\n",
                "\n",
                "# Apply Transformation\n",
                "source.transform(result_ransac.transformation)\n",
                "o3d.visualization.draw_geometries([source, target], window_name=\"After Global Registration\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Local Refinement (ICP)\n",
                "\n",
                "Now that the clouds are roughly aligned, we use **Iterative Closest Point (ICP)** to perfect the match. We use a smaller threshold here."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ensure normals are estimated for the original dense clouds\n",
                "source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size, max_nn=30))\n",
                "target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size, max_nn=30))\n",
                "\n",
                "# Threshold for ICP (Usually smaller than global)\n",
                "icp_threshold = voxel_size * 0.4\n",
                "\n",
                "start = time.time()\n",
                "result_icp = o3d.pipelines.registration.registration_icp(\n",
                "    source, target, icp_threshold, np.identity(4), # Source is already transformed, so initial guess is Identity\n",
                "    o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
                ")\n",
                "print(f\"ICP Refinement took {time.time() - start:.2f} sec.\")\n",
                "print(\"Refined Transformation:\\n\", result_icp.transformation)\n",
                "\n",
                "# Apply Final Transformation (Note: this adds to the previous one)\n",
                "source.transform(result_icp.transformation)\n",
                "source.paint_uniform_color([1, 0, 0]) # Red for final alignment\n",
                "o3d.visualization.draw_geometries([source, target], window_name=\"Final ICP Registration\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}