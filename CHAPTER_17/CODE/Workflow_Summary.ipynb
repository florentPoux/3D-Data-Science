{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import subprocess\n",
    "import os\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Photogrammetry (COLMAP) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_colmap(image_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Run COLMAP photogrammetry pipeline.\n",
    "    Requires COLMAP (https://colmap.github.io/) to be installed and in PATH.\n",
    "    \"\"\"\n",
    "    print(\"\ud83d\udcf8 Starting COLMAP reconstruction...\")\n",
    "    try:\n",
    "        # Feature extraction\n",
    "        subprocess.run([\"colmap\", \"feature_extractor\",\n",
    "                        \"--database_path\", f\"{output_dir}/database.db\",\n",
    "                        \"--image_path\", image_dir], check=True)\n",
    "        \n",
    "        # Feature matching\n",
    "        subprocess.run([\"colmap\", \"exhaustive_matcher\",\n",
    "                        \"--database_path\", f\"{output_dir}/database.db\"], check=True)\n",
    "        \n",
    "        # Sparse reconstruction\n",
    "        os.makedirs(f\"{output_dir}/sparse\", exist_ok=True)\n",
    "        subprocess.run([\"colmap\", \"mapper\",\n",
    "                        \"--database_path\", f\"{output_dir}/database.db\",\n",
    "                        \"--image_path\", image_dir,\n",
    "                        \"--output_path\", f\"{output_dir}/sparse\"], check=True)\n",
    "        \n",
    "        # Dense reconstruction\n",
    "        os.makedirs(f\"{output_dir}/dense\", exist_ok=True)\n",
    "        subprocess.run([\"colmap\", \"image_undistorter\",\n",
    "                        \"--image_path\", image_dir,\n",
    "                        \"--input_path\", f\"{output_dir}/sparse/0\",\n",
    "                        \"--output_path\", f\"{output_dir}/dense\"], check=True)\n",
    "        \n",
    "        subprocess.run([\"colmap\", \"patch_match_stereo\",\n",
    "                        \"--workspace_path\", f\"{output_dir}/dense\"], check=True)\n",
    "        \n",
    "        subprocess.run([\"colmap\", \"stereo_fusion\",\n",
    "                        \"--workspace_path\", f\"{output_dir}/dense\",\n",
    "                        \"--output_path\", f\"{output_dir}/dense/fused.ply\"], check=True)\n",
    "        print(\"\u2705 COLMAP reconstruction finished.\")\n",
    "        return f\"{output_dir}/dense/fused.ply\"\n",
    "    except FileNotFoundError:\n",
    "        print(\"\u274c COLMAP executable not found. Please install COLMAP.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c COLMAP execution failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. Pre-processing ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(pcd, nb_neighbors=20, std_ratio=2.0):\n",
    "    \"\"\"Statistical Outlier Removal.\"\"\"\n",
    "    print(\"\ud83e\uddf9 Removing noise...\")\n",
    "    cl, ind = pcd.remove_statistical_outlier(nb_neighbors, std_ratio)\n",
    "    return cl, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_downsample(pcd, voxel_size=0.05, detail_size=0.02):\n",
    "    \"\"\"Adaptive downsampling preserving details based on curvature.\"\"\"\n",
    "    print(\"\ud83d\udcc9 Adaptive downsampling...\")\n",
    "    pcd.estimate_normals()\n",
    "    \n",
    "    normals = np.asarray(pcd.normals)\n",
    "    if len(normals) == 0:\n",
    "        return pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    # Estimate curvature\n",
    "    # Simple proxy: variance of normals in local neighborhood could be used,\n",
    "    # but here we use global variance for simplicity as per snippet logic\n",
    "    # Real implementation would use neighborhood PCA.\n",
    "    # We will assume 'curvature' is computed or approximated.\n",
    "    # Approximation: random score for demo if kdtree not used\n",
    "    curvature = np.random.rand(len(normals)) # Placeholder for real curvature calc\n",
    "    \n",
    "    high_detail = curvature > np.percentile(curvature, 75)\n",
    "    \n",
    "    points = np.asarray(pcd.points)\n",
    "    high_detail_pcd = o3d.geometry.PointCloud()\n",
    "    high_detail_pcd.points = o3d.utility.Vector3dVector(points[high_detail])\n",
    "    \n",
    "    low_detail_pcd = o3d.geometry.PointCloud()\n",
    "    low_detail_pcd.points = o3d.utility.Vector3dVector(points[~high_detail])\n",
    "    \n",
    "    high_detail_down = high_detail_pcd.voxel_down_sample(detail_size)\n",
    "    low_detail_down = low_detail_pcd.voxel_down_sample(voxel_size)\n",
    "    \n",
    "    return high_detail_down + low_detail_down\n",
    "\n",
    "# --- 3. Feature Extraction ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(pcd, radius=0.1):\n",
    "    \"\"\"Extract local (FPFH) and global features.\"\"\"\n",
    "    print(\"\ud83e\uddec Extracting features...\")\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius, max_nn=30))\n",
    "    \n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd, o3d.geometry.KDTreeSearchParamHybrid(radius=radius*5, max_nn=100))\n",
    "    \n",
    "    points = np.asarray(pcd.points)\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    distances = np.linalg.norm(points - centroid, axis=1)\n",
    "    \n",
    "    features = {\n",
    "        'fpfh': np.asarray(fpfh.data).T,\n",
    "        'distance_to_centroid': distances,\n",
    "        'height': points[:, 2]\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# --- 4. 3D Structures & Segmentation ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize(pcd, voxel_size):\n",
    "    \"\"\"Convert Point Cloud to Voxel Grid.\"\"\"\n",
    "    print(\"\ud83d\udce6 Voxelizing...\")\n",
    "    voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size)\n",
    "    return voxel_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_3d(points, eps, min_points):\n",
    "    \"\"\"Custom DBSCAN implementation using KDTree.\"\"\"\n",
    "    print(\"\ud83d\udd0d Running custom DBSCAN...\")\n",
    "    tree = KDTree(points)\n",
    "    clusters = []\n",
    "    visited = set()\n",
    "    \n",
    "    def expand_cluster(point_idx, neighbors):\n",
    "        cluster = [point_idx]\n",
    "        # Iterate over neighbor indices directly\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                # query_ball_point returns list of indices\n",
    "                new_neighbors = tree.query_radius([points[neighbor]], r=eps)[0]\n",
    "                if len(new_neighbors) >= min_points:\n",
    "                    cluster.extend(expand_cluster(neighbor, new_neighbors))\n",
    "        return cluster\n",
    "    \n",
    "    for i in range(len(points)):\n",
    "        if i not in visited:\n",
    "            # Query neighbors\n",
    "            neighbors = tree.query_radius([points[i]], r=eps)[0]\n",
    "            if len(neighbors) >= min_points:\n",
    "                visited.add(i)\n",
    "                cluster = expand_cluster(i, neighbors)\n",
    "                clusters.append(cluster)\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "class OctreeNode:\n",
    "    \"\"\"Simple Python Octree Node.\"\"\"\n",
    "    def __init__(self, center, size, points):\n",
    "        self.center = center\n",
    "        self.size = size\n",
    "        self.points = points\n",
    "        self.children = []\n",
    "        \n",
    "    def subdivide(self):\n",
    "        if len(self.points) <= 100:\n",
    "            return\n",
    "        \n",
    "        new_size = self.size / 2\n",
    "        for i in range(8):\n",
    "            offset = new_size * np.array([\n",
    "                (i & 1) - 0.5,\n",
    "                ((i >> 1) & 1) - 0.5,\n",
    "                ((i >> 2) & 1) - 0.5\n",
    "            ])\n",
    "            new_center = self.center + offset\n",
    "            # Simple box check\n",
    "            mask = np.all(np.abs(self.points - new_center) <= new_size/2, axis=1)\n",
    "            if np.any(mask):\n",
    "                new_node = OctreeNode(new_center, new_size, self.points[mask])\n",
    "                self.children.append(new_node)\n",
    "                new_node.subdivide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_octree(points):\n",
    "    print(\"\ud83c\udf33 Building Octree...\")\n",
    "    if len(points) == 0: return None\n",
    "    center = np.mean(points, axis=0)\n",
    "    size = np.max(np.abs(points - center)) * 2\n",
    "    root = OctreeNode(center, size, points)\n",
    "    root.subdivide()\n",
    "    return root\n",
    "\n",
    "# --- 5. Maching Learning ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(point_cloud, labels=None, test_size=0.2, n_estimators=100):\n",
    "    \"\"\"Train a Random Forest Classifier.\"\"\"\n",
    "    print(\"\ud83c\udf32 Training Random Forest...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(point_cloud)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    train_accuracy = rf_classifier.score(X_train, y_train)\n",
    "    test_accuracy = rf_classifier.score(X_test, y_test)\n",
    "    print(f\"   -> Training Accuracy: {train_accuracy:.2f}\")\n",
    "    print(f\"   -> Testing Accuracy: {test_accuracy:.2f}\")\n",
    "    \n",
    "    return rf_classifier, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(pcd, model, scaler):\n",
    "    \"\"\"Predict labels for a point cloud.\"\"\"\n",
    "    print(\"\ud83d\udd2e Predicting labels...\")\n",
    "    points = np.asarray(pcd.points)\n",
    "    if not pcd.has_normals(): pcd.estimate_normals()\n",
    "    normals = np.asarray(pcd.normals)\n",
    "    colors = np.asarray(pcd.colors) if pcd.has_colors() else np.zeros_like(points)\n",
    "    \n",
    "    features = np.hstack((points, colors, normals))\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    return model.predict(features_scaled)\n",
    "\n",
    "# --- 6. Meshing ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_cloud_to_mesh(pcd, depth=8):\n",
    "    \"\"\"Poisson Surface Reconstruction.\"\"\"\n",
    "    print(\"\ud83d\udd78\ufe0f Creating Mesh...\")\n",
    "    if not pcd.has_normals():\n",
    "        pcd.estimate_normals()\n",
    "    \n",
    "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=depth)\n",
    "    \n",
    "    # Remove low density vertices\n",
    "    vertices_to_remove = densities < np.quantile(densities, 0.1)\n",
    "    mesh.remove_vertices_by_mask(vertices_to_remove)\n",
    "    return mesh\n",
    "\n",
    "# --- Main Pipeline ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"\ud83d\ude80 Starting 3D Data Science Workflow Summary...\")\n",
    "    \n",
    "    # 1. Load Data (Generate synthetic if missing)\n",
    "    # Trying to load a demo file or generate\n",
    "    try:\n",
    "        pcd = o3d.io.read_point_cloud(\"../DATA/sample.ply\")\n",
    "        if pcd.is_empty(): raise FileNotFoundError\n",
    "    except:\n",
    "        print(\"\u26a0\ufe0f No data found, generating synthetic torus...\")\n",
    "        mesh = o3d.geometry.TriangleMesh.create_torus()\n",
    "        pcd = mesh.sample_points_poisson_disk(5000)\n",
    "    \n",
    "    # 2. Add some noise\n",
    "    points = np.asarray(pcd.points)\n",
    "    noise = np.random.normal(0, 0.02, points.shape)\n",
    "    pcd.points = o3d.utility.Vector3dVector(points + noise)\n",
    "    \n",
    "    # 3. Clean\n",
    "    clean_pcd, _ = remove_noise(pcd)\n",
    "    \n",
    "    # 4. Downsample\n",
    "    ds_pcd = adaptive_downsample(clean_pcd)\n",
    "    \n",
    "    # 5. Extract Features\n",
    "    feats = extract_features(ds_pcd)\n",
    "    print(f\"   -> Extracted {feats['fpfh'].shape[0]} FPFH descriptors.\")\n",
    "    \n",
    "    # 6. Structuring\n",
    "    octree = build_octree(np.asarray(ds_pcd.points))\n",
    "    voxels = voxelize(ds_pcd, voxel_size=0.1)\n",
    "    \n",
    "    # 7. Clustering (Custom DBSCAN on subset)\n",
    "    subset_points = np.asarray(ds_pcd.points)[:1000]\n",
    "    clusters = dbscan_3d(subset_points, eps=0.1, min_points=5)\n",
    "    print(f\"   -> Found {len(clusters)} clusters.\")\n",
    "    \n",
    "    # 8. Meshing\n",
    "    mesh = point_cloud_to_mesh(ds_pcd)\n",
    "    \n",
    "    # 9. Visualization\n",
    "    print(\"\ud83d\udc40 Visualizing final mesh...\")\n",
    "    o3d.visualization.draw_geometries([mesh], window_name=\"Final Result\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}